{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadania\n",
    "1. Utwórz dwie nowe kolumny w ramce \"Countries\", w których powierzchnia i gęstość zaludnienia wyrażone sa odpowiednio w milach kwadratowych i osobach na milę kwadratową. \n",
    "  - Przelicznik: 1 mila kwadratowa = 0.38610 km kwadratowego (powierzchnię należy pomnożyć, a gęstość zaludnienia podzielić przez ten współczynnik)\n",
    "  - Typami nowych kolumn mają być odpowiednio integer (powierzchnia) i float (gęstość). Zaokrąglanie do integer: \"int(x)\"\n",
    "  - Nazwy nowych kolumn proszę ustawić odpowiednio na '<tt>Area (sq mi)</tt>' oraz '<tt>Pop Density (per sq mi)</tt>'\n",
    "1. Na wykresie scatterplot narysuj zależność liczby lotnisk od powierzchni kraju. \n",
    "  - Dane potrzebne do wykresu są w dwóch ramkach (Countries i Airports), konieczne więc będzie ich złączenie (join).\n",
    "  - Wskazówka: w pierwszym etapie stwórz ramkę agregującą liczbę lotnisk w zależności od kraju. W drugim etapie złącz (join) tę ramkę z ramką countries. Kolumną wspólną (warunkiem złączenia) będzie Country.\n",
    "  - Nie zawsze nazwy tych samych krajów będą identyczne w obu ramkach, co może stanowić problem (złączenie nie powstanie). Zastanów się jak przy pomocy mechanizmu złączeń wykryć, które nazwy się różnią. Stwórz odpowiednią ramkę, która zawiera takie nazwy. \n",
    "  - Następnie zmień nazwy kilku największych państw w jednej z ramek, tak żeby ujednolicić nazwy. Można to zrobić funkcją replace:\n",
    "<br><tt>cdf=cdf.replace(['Korea, South', 'Korea, North'], ['South Korea', 'North Korea'], 'Country')</tt>\n",
    "1. Do ramki \"Countries\" dodaj nową kolumnę \"Continent\" (według klasyfikacji Africa, Asia, Europe, North America, South America, Antarctica, Australia/Oceania). \n",
    "  - Skorzystaj z kolumny \"Region\" i pomocniczej funkcji (UDF) mapującej region na kontynent.\n",
    "1. Oblicz, ile lotnisk jest na poszczególnych kontynentach. To zadanie również wymaga złączenia ramek \"Countries\" i \"Airports\". Wynik przedstaw na wykresie słupkowym.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wbudowane funkcje, które mogą być przydatne:\n",
    "# - udf: służy do tworzenia funkcji użytkownika\n",
    "# - trim: usuwa białe spacje z początku i końca stringu\n",
    "# - isnull: testuje, czy wartość jest pusta\n",
    "from pyspark.sql.functions import col, udf, trim, isnull\n",
    "from pyspark.sql.types import FloatType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_float (s) :\n",
    "   return float(s.replace(',','.'))\n",
    "float_udf = udf(to_float , FloatType())\n",
    "\n",
    "def to_int (s) :\n",
    "   return int(s)\n",
    "int_udf = udf(to_int , IntegerType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "countries = spark.read.csv(\"countries of the world.csv\",inferSchema=True,header=True)\n",
    "\n",
    "# Usuwa kropki z wszystkich nazw kolumn (powodują wiele błędów, prawdopodobnie bug w Sparku)\n",
    "# (Nb. wszystkie inne metody zmiany tych nazw (np. użycie columnRenamed) zawiodły)\n",
    "new_columns=[s.replace('.','') for s in countries.columns]\n",
    "countries=countries.toDF(*new_columns) # tutaj '*' to operator \"splat\" -- robi z tablicy listę argumentów\n",
    "\n",
    "# Tak można ustawić wyświetlanie większej liczby wierszy w Jupyterze\n",
    "pd.set_option('display.max_rows', 20)\n",
    "#display(countries.limit(5).toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>Population</th>\n",
       "      <th>Area (sq mi)</th>\n",
       "      <th>Pop Density (per sq mi)</th>\n",
       "      <th>Coastline (coast/area ratio)</th>\n",
       "      <th>Net migration</th>\n",
       "      <th>Infant mortality (per 1000 births)</th>\n",
       "      <th>GDP ($ per capita)</th>\n",
       "      <th>Literacy (%)</th>\n",
       "      <th>Phones (per 1000)</th>\n",
       "      <th>Arable (%)</th>\n",
       "      <th>Crops (%)</th>\n",
       "      <th>Other (%)</th>\n",
       "      <th>Birthrate</th>\n",
       "      <th>Deathrate</th>\n",
       "      <th>Agriculture</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>ASIA (EX. NEAR EAST)</td>\n",
       "      <td>31056997</td>\n",
       "      <td>647500</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.059999</td>\n",
       "      <td>163.070007</td>\n",
       "      <td>700</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>12.13</td>\n",
       "      <td>0.22</td>\n",
       "      <td>87.650002</td>\n",
       "      <td>46.599998</td>\n",
       "      <td>20.34</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>EASTERN EUROPE</td>\n",
       "      <td>3581655</td>\n",
       "      <td>28748</td>\n",
       "      <td>124.599998</td>\n",
       "      <td>1.26</td>\n",
       "      <td>-4.930000</td>\n",
       "      <td>21.520000</td>\n",
       "      <td>4500</td>\n",
       "      <td>86.5</td>\n",
       "      <td>71.199997</td>\n",
       "      <td>21.09</td>\n",
       "      <td>4.42</td>\n",
       "      <td>74.489998</td>\n",
       "      <td>15.110000</td>\n",
       "      <td>5.22</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country                Region  Population  Area (sq mi)  \\\n",
       "0  Afghanistan  ASIA (EX. NEAR EAST)    31056997        647500   \n",
       "1      Albania        EASTERN EUROPE     3581655         28748   \n",
       "\n",
       "   Pop Density (per sq mi)  Coastline (coast/area ratio)  Net migration  \\\n",
       "0                48.000000                          0.00      23.059999   \n",
       "1               124.599998                          1.26      -4.930000   \n",
       "\n",
       "   Infant mortality (per 1000 births)  GDP ($ per capita)  Literacy (%)  \\\n",
       "0                          163.070007                 700          36.0   \n",
       "1                           21.520000                4500          86.5   \n",
       "\n",
       "   Phones (per 1000)  Arable (%)  Crops (%)  Other (%)  Birthrate  Deathrate  \\\n",
       "0           3.200000       12.13       0.22  87.650002  46.599998      20.34   \n",
       "1          71.199997       21.09       4.42  74.489998  15.110000       5.22   \n",
       "\n",
       "   Agriculture  Industry  Service  \n",
       "0        0.380     0.240    0.380  \n",
       "1        0.232     0.188    0.579  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utworzenie nowej ramki 'cdf':\n",
    "# - wartosci puste wypelnione \"-1\", zeby nie usuwac wierszy\n",
    "# - trim stringów (w nazwach występują niepożądane spacje na końcu)\n",
    "# - konwersja wszystkich kolumn zmiennoprzecinkowych na float\n",
    "# - zmiana 'sq mi' na 'sq km', bo w zbiorze wartości są faktycznie w km^2, a nie milach^2\n",
    "cdf=countries.na.fill(\"-1\").select( \n",
    "                 trim(col('Country')).alias('Country'),\\\n",
    "                 trim(col('Region')).alias('Region'),'Population',\\\n",
    "                 col('`Area (sq mi)`').alias('Area (sq mi)'),\\\n",
    "                 float_udf('`Pop Density (per sq mi)`').alias('Pop Density (per sq mi)'),\\\n",
    "                 float_udf('Coastline (coast/area ratio)').alias('Coastline (coast/area ratio)'),\\\n",
    "                 float_udf('Net migration').alias('Net migration'),\\\n",
    "                 float_udf('Infant mortality (per 1000 births)').alias('Infant mortality (per 1000 births)'),\\\n",
    "                 'GDP ($ per capita)',\\\n",
    "                 float_udf('Literacy (%)').alias('Literacy (%)'),\\\n",
    "                 float_udf('Phones (per 1000)').alias('Phones (per 1000)'),\\\n",
    "                 float_udf('Arable (%)').alias('Arable (%)'),\\\n",
    "                 float_udf('Crops (%)').alias('Crops (%)'),\\\n",
    "                 float_udf('Other (%)').alias('Other (%)'),\\\n",
    "                 float_udf('Birthrate').alias('Birthrate'),\\\n",
    "                 float_udf('Deathrate').alias('Deathrate'),\\\n",
    "                 float_udf('Agriculture').alias('Agriculture'),\\\n",
    "                 float_udf('Industry').alias('Industry'),\\\n",
    "                 float_udf('Service').alias('Service'))\n",
    "cdf.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 1: nowe kolumny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>Population</th>\n",
       "      <th>Area (sq mi)</th>\n",
       "      <th>Pop Density (per sq mi)</th>\n",
       "      <th>Coastline (coast/area ratio)</th>\n",
       "      <th>Net migration</th>\n",
       "      <th>Infant mortality (per 1000 births)</th>\n",
       "      <th>GDP ($ per capita)</th>\n",
       "      <th>Literacy (%)</th>\n",
       "      <th>...</th>\n",
       "      <th>Arable (%)</th>\n",
       "      <th>Crops (%)</th>\n",
       "      <th>Other (%)</th>\n",
       "      <th>Birthrate</th>\n",
       "      <th>Deathrate</th>\n",
       "      <th>Agriculture</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Service</th>\n",
       "      <th>Area (sq km)</th>\n",
       "      <th>Pop Density (per sq km)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>ASIA (EX. NEAR EAST)</td>\n",
       "      <td>31056997</td>\n",
       "      <td>647500</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.059999</td>\n",
       "      <td>163.070007</td>\n",
       "      <td>700</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.13</td>\n",
       "      <td>0.22</td>\n",
       "      <td>87.650002</td>\n",
       "      <td>46.599998</td>\n",
       "      <td>20.34</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.380</td>\n",
       "      <td>96524</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>EASTERN EUROPE</td>\n",
       "      <td>3581655</td>\n",
       "      <td>28748</td>\n",
       "      <td>124.599998</td>\n",
       "      <td>1.26</td>\n",
       "      <td>-4.930000</td>\n",
       "      <td>21.520000</td>\n",
       "      <td>4500</td>\n",
       "      <td>86.5</td>\n",
       "      <td>...</td>\n",
       "      <td>21.09</td>\n",
       "      <td>4.42</td>\n",
       "      <td>74.489998</td>\n",
       "      <td>15.110000</td>\n",
       "      <td>5.22</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.579</td>\n",
       "      <td>4285</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country                Region  Population  Area (sq mi)  \\\n",
       "0  Afghanistan  ASIA (EX. NEAR EAST)    31056997        647500   \n",
       "1      Albania        EASTERN EUROPE     3581655         28748   \n",
       "\n",
       "   Pop Density (per sq mi)  Coastline (coast/area ratio)  Net migration  \\\n",
       "0                48.000000                          0.00      23.059999   \n",
       "1               124.599998                          1.26      -4.930000   \n",
       "\n",
       "   Infant mortality (per 1000 births)  GDP ($ per capita)  Literacy (%)  \\\n",
       "0                          163.070007                 700          36.0   \n",
       "1                           21.520000                4500          86.5   \n",
       "\n",
       "            ...             Arable (%)  Crops (%)  Other (%)  Birthrate  \\\n",
       "0           ...                  12.13       0.22  87.650002  46.599998   \n",
       "1           ...                  21.09       4.42  74.489998  15.110000   \n",
       "\n",
       "   Deathrate  Agriculture  Industry  Service  Area (sq km)  \\\n",
       "0      20.34        0.380     0.240    0.380         96524   \n",
       "1       5.22        0.232     0.188    0.579          4285   \n",
       "\n",
       "   Pop Density (per sq km)  \n",
       "0                        7  \n",
       "1                       18  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf = cdf.withColumn('Area (sq km)',int_udf(col('Area (sq mi)')*0.38610*0.38610))\n",
    "cdf = cdf.withColumn('Pop Density (per sq km)',int_udf(col('Pop Density (per sq mi)')*0.38610*0.38610))\n",
    "cdf.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuesA = [('Pirate',1),('Monkey',2),('Ninja',3),('Spaghetti',4)]\n",
    "TableA = spark.createDataFrame(valuesA,['name','id'])\n",
    " \n",
    "valuesB = [('Rutabaga',1),('Pirate',2),('Ninja',3),('Darth Vader',4)]\n",
    "TableB = spark.createDataFrame(valuesB,['name','id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=TableA.alias('a')\n",
    "b=TableB.alias('b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+------+----+\n",
      "|     name| id|  name|  id|\n",
      "+---------+---+------+----+\n",
      "|Spaghetti|  4|  null|null|\n",
      "|    Ninja|  3| Ninja|   3|\n",
      "|   Pirate|  1|Pirate|   2|\n",
      "|   Monkey|  2|  null|null|\n",
      "+---------+---+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a.join(b, a.name==b.name, how='left').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----------+---+\n",
      "|  name|  id|       name| id|\n",
      "+------+----+-----------+---+\n",
      "|  null|null|   Rutabaga|  1|\n",
      "| Ninja|   3|      Ninja|  3|\n",
      "|Pirate|   1|     Pirate|  2|\n",
      "|  null|null|Darth Vader|  4|\n",
      "+------+----+-----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a.join(b, a.name==b.name, how='right').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+-----------+----+\n",
      "|     name|  id|       name|  id|\n",
      "+---------+----+-----------+----+\n",
      "|     null|null|   Rutabaga|   1|\n",
      "|Spaghetti|   4|       null|null|\n",
      "|    Ninja|   3|      Ninja|   3|\n",
      "|   Pirate|   1|     Pirate|   2|\n",
      "|   Monkey|   2|       null|null|\n",
      "|     null|null|Darth Vader|   4|\n",
      "+---------+----+-----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a.join(b, a.name==b.name, how='full_outer').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 2: zależność liczby lotnisk od powierzchni kraju "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the airports data\n",
    "arp = spark.read.csv(\"airportsAll.csv\",inferSchema=True,header=False).\\\n",
    "toDF(\"id\",\"airport\",\"city\",\"country\",\"iata\",\"icao\",\"latitude\",\"longitude\",\"altitude\",\"timezone\",\"dst\",\"tz_timezone\",\"type\",\"data_source\")\n",
    "# zacznij od stworzenia ramki, która zawiera posortowaną liczbę lotnisk w poszczególnych krajach\n",
    "arpByCountry = arp.groupBy(col('country')).count().orderBy('country')\n",
    "\n",
    "#arpByCountry.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0cf04e6780>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO złączenie ramek i wykres\n",
    "cdf=cdf.replace(['Antigua & Barbuda','British Virgin Is.','Saint Kitts & Nevis','Gambia, The'], \n",
    "                ['Antigua and Barbuda','British Virgin Islands','Saint Kitts and Nevis','Gambia'],\n",
    "                'Country')\n",
    "a = cdf.alias('a')\n",
    "c= arpByCountry.alias('c')\n",
    "a.join(c, a.Country==c.country).toPandas().plot(x=\"count\",y=\"Area (sq km)\",kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 53314)\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1188, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1014, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1193, in send_command\n",
      "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/dataframe.py\", line 533, in collect\n",
      "    sock_info = self._jdf.collectToPython()\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1286, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/protocol.py\", line 336, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o622.collectToPython\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:33277)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 958, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1096, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "Py4JNetworkError",
     "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:33277)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1285\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1286\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0;34m\"An error occurred while calling {0}{1}{2}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                 format(target_id, \".\", name))\n\u001b[0m\u001b[1;32m    337\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o622.collectToPython",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    959\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-75d2d4f7a46d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#c1.toPandas()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCountry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mtoPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m         \u001b[0;31m# Below is toPandas without Arrow optimization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2142\u001b[0;31m         \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \"\"\"\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.4.0-bin-hadoop2.7/python/pyspark/traceback_utils.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, tb)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark_stack_depth\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark_stack_depth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetCallSite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1282\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1286\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1010\u001b[0m          \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \"\"\"\n\u001b[0;32m-> 1012\u001b[0;31m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    964\u001b[0m         connection = GatewayConnection(\n\u001b[1;32m    965\u001b[0m             self.gateway_parameters, self.gateway_property)\n\u001b[0;32m--> 966\u001b[0;31m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1106\u001b[0m                 \u001b[0;34m\"server ({0}:{1})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1108\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_authenticate_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:33277)"
     ]
    }
   ],
   "source": [
    "# TODO wykrycie niepasujących nazw państwa i ujednolicenie wartości \n",
    "ac = a.join(c, a.Country==c.country, how='full_outer').\\\n",
    "filter((col('a.Country').isNull()) | (col('c.country').isNull()) )\n",
    "\n",
    "a1 = ac.\\\n",
    "filter(col('a.Country').isNull() != 1).\\\n",
    "select(col('a.Country'))\n",
    "#a1.toPandas()\n",
    "\n",
    "c1 = ac.\\\n",
    "filter(col('c.country').isNull() != 1).\\\n",
    "select(col('c.country'))\n",
    "#c1.toPandas()\n",
    "\n",
    "a1.join(c1, a1.Country.substr(1, 3)==c1.country.substr(1, 3)).toPandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
